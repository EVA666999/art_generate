# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ llama-cpp-python

–≠—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ —É—Å—Ç–∞–Ω–æ–≤–∫–µ `llama-cpp-python` –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å GGUF –º–æ–¥–µ–ª—è–º–∏ –≤ –ø—Ä–æ–µ–∫—Ç–µ.

## üöÄ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ (–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

### –î–ª—è Windows:
```bash
# –ê–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ
venv\Scripts\activate

# –ó–∞–ø—É—Å—Ç–∏—Ç–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–∫—Ä–∏–ø—Ç
install_llama_cpp.bat
```

### –î–ª—è Linux/macOS:
```bash
# –ê–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ
source venv/bin/activate

# –ó–∞–ø—É—Å—Ç–∏—Ç–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–∫—Ä–∏–ø—Ç
python install_llama_cpp.py
```

## üîß –†—É—á–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞

### 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA

–ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å NVIDIA GPU —Å CUDA:

```bash
# –£–¥–∞–ª–∏—Ç–µ —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —É—Å—Ç–∞–Ω–æ–≤–∫—É (–µ—Å–ª–∏ –µ—Å—Ç—å)
pip uninstall llama-cpp-python -y

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –≤–µ—Ä—Å–∏—é —Å CUDA 12.1
pip install llama-cpp-python --force-reinstall --index-url https://jllllll.github.io/llama-cpp-python-cuBLAS-wheels/cu121

# –ò–ª–∏ –¥–ª—è CUDA 12.0
pip install llama-cpp-python --force-reinstall --index-url https://jllllll.github.io/llama-cpp-python-cuBLAS-wheels/cu120

# –ò–ª–∏ –¥–ª—è CUDA 11.8
pip install llama-cpp-python --force-reinstall --index-url https://jllllll.github.io/llama-cpp-python-cuBLAS-wheels/cu118
```

### 2. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç–æ–ª—å–∫–æ –¥–ª—è CPU

–ï—Å–ª–∏ —É –≤–∞—Å –Ω–µ—Ç GPU –∏–ª–∏ —Ö–æ—Ç–∏—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ CPU:

```bash
# –£–¥–∞–ª–∏—Ç–µ —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —É—Å—Ç–∞–Ω–æ–≤–∫—É (–µ—Å–ª–∏ –µ—Å—Ç—å)
pip uninstall llama-cpp-python -y

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ CPU –≤–µ—Ä—Å–∏—é
pip install llama-cpp-python --force-reinstall
```

## üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏

–ü–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –≤—Å–µ —Ä–∞–±–æ—Ç–∞–µ—Ç:

```python
import llama_cpp
print(f"llama_cpp –≤–µ—Ä—Å–∏—è: {llama_cpp.__version__}")

# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å CUDA (–µ—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –≤–µ—Ä—Å–∏—è —Å CUDA)
if hasattr(llama_cpp, 'Llama'):
    print("‚úÖ –ö–ª–∞—Å—Å Llama –¥–æ—Å—Ç—É–ø–µ–Ω")
else:
    print("‚ùå –ö–ª–∞—Å—Å Llama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
```

## üêõ –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º

### –û—à–∏–±–∫–∞: "Could not find module 'llama.dll'"

–≠—Ç–∞ –æ—à–∏–±–∫–∞ –≤–æ–∑–Ω–∏–∫–∞–µ—Ç, –∫–æ–≥–¥–∞ –Ω–∞—Ç–∏–≤–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ.

**–†–µ—à–µ–Ω–∏–µ:**
1. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –≤–µ—Ä—Å–∏—é –¥–ª—è –≤–∞—à–µ–π –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã
2. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–∫—Ä–∏–ø—Ç: `python install_llama_cpp.py`
3. –î–ª—è Windows —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É –≤–∞—Å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã Visual C++ Redistributables

### –û—à–∏–±–∫–∞: "CUDA not available"

**–†–µ—à–µ–Ω–∏–µ:**
1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ —É –≤–∞—Å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω CUDA Toolkit
2. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ PyTorch –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç CUDA: `python -c "import torch; print(torch.cuda.is_available())"`
3. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –≤–µ—Ä—Å–∏—é llama-cpp-python —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA

### –û—à–∏–±–∫–∞: "ImportError: DLL load failed"

**–†–µ—à–µ–Ω–∏–µ:**
1. –ü–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ llama-cpp-python —Å —Ñ–ª–∞–≥–æ–º `--force-reinstall`
2. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É –≤–∞—Å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Å–∏—Å—Ç–µ–º–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
3. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ CPU –≤–µ—Ä—Å–∏—é, –µ—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º—ã —Å CUDA

## üìã –°–∏—Å—Ç–µ–º–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

### Windows:
- Python 3.8+
- Visual C++ Redistributables
- CUDA Toolkit (–¥–ª—è GPU –≤–µ—Ä—Å–∏–∏)

### Linux:
- Python 3.8+
- GCC/G++ –∫–æ–º–ø–∏–ª—è—Ç–æ—Ä
- CUDA Toolkit (–¥–ª—è GPU –≤–µ—Ä—Å–∏–∏)

### macOS:
- Python 3.8+
- Xcode Command Line Tools
- Metal Performance Shaders (–¥–ª—è GPU –≤–µ—Ä—Å–∏–∏)

## üîó –ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏

- [llama-cpp-python GitHub](https://github.com/abetlen/llama-cpp-python)
- [CUDA –≤–µ—Ä—Å–∏–∏ –¥–ª—è Windows](https://jllllll.github.io/llama-cpp-python-cuBLAS-wheels/)
- [PyTorch CUDA —É—Å—Ç–∞–Ω–æ–≤–∫–∞](https://pytorch.org/get-started/locally/)

## üìù –ü—Ä–∏–º–µ—á–∞–Ω–∏—è

- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–∫—Ä–∏–ø—Ç –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å CUDA –∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –≤–µ—Ä—Å–∏—é
- –ï—Å–ª–∏ CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è CPU –≤–µ—Ä—Å–∏—è
- –ü–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–µ—Ä–≤–µ—Ä: `python app/main.py` 