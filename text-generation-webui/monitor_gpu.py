#!/usr/bin/env python3
"""
GPU Performance Monitor for Text Generation WebUI
–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ GPU –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏
"""

import subprocess
import time
import json
import os
from datetime import datetime
from typing import Dict, List, Optional

class GPUMonitor:
    """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ GPU"""
    
    def __init__(self, log_file: str = "gpu_performance.log"):
        self.log_file = log_file
        self.start_time = time.time()
        
    def get_gpu_info(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ GPU"""
        try:
            result = subprocess.run(
                ["nvidia-smi", "--query-gpu=name,memory.total,memory.used,memory.free,utilization.gpu,temperature.gpu,power.draw", 
                 "--format=csv,noheader,nounits"],
                capture_output=True, text=True, check=True
            )
            
            lines = result.stdout.strip().split('\n')
            gpu_data = {}
            
            for i, line in enumerate(lines):
                parts = line.split(', ')
                if len(parts) >= 7:
                    gpu_data[f"GPU_{i}"] = {
                        "name": parts[0],
                        "memory_total_mb": int(parts[1]),
                        "memory_used_mb": int(parts[2]),
                        "memory_free_mb": int(parts[3]),
                        "utilization_gpu": int(parts[4]),
                        "temperature_c": int(parts[5]),
                        "power_w": float(parts[6]) if parts[6] != "N/A" else 0
                    }
            
            return gpu_data
            
        except subprocess.CalledProcessError as e:
            print(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ GPU: {e}")
            return {}
        except Exception as e:
            print(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
            return {}
    
    def calculate_performance_metrics(self, gpu_data: Dict) -> Dict:
        """–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        if not gpu_data:
            return {}
        
        metrics = {}
        for gpu_id, gpu_info in gpu_data.items():
            # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
            memory_usage_pct = (gpu_info["memory_used_mb"] / gpu_info["memory_total_mb"]) * 100
            
            # –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏
            memory_efficiency = gpu_info["memory_used_mb"] / max(gpu_info["memory_total_mb"], 1)
            
            # –û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (0-100)
            performance_score = (
                (gpu_info["utilization_gpu"] * 0.4) +  # –£—Ç–∏–ª–∏–∑–∞—Ü–∏—è GPU 40%
                (memory_efficiency * 40) +              # –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–∞–º—è—Ç–∏ 40%
                (min(gpu_info["temperature_c"] / 80, 1) * 20)  # –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ 20%
            )
            
            metrics[gpu_id] = {
                "memory_usage_pct": round(memory_usage_pct, 1),
                "memory_efficiency": round(memory_efficiency, 3),
                "performance_score": round(performance_score, 1),
                "is_optimal": memory_usage_pct > 80 and gpu_info["utilization_gpu"] > 50
            }
        
        return metrics
    
    def log_performance(self, gpu_data: Dict, metrics: Dict):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        uptime = time.time() - self.start_time
        
        log_entry = {
            "timestamp": timestamp,
            "uptime_seconds": round(uptime, 1),
            "gpu_data": gpu_data,
            "performance_metrics": metrics
        }
        
        # –ó–∞–ø–∏—Å—å –≤ –ª–æ–≥ —Ñ–∞–π–ª
        with open(self.log_file, "a", encoding="utf-8") as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")
        
        # –í—ã–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª—å
        print(f"\n=== GPU Performance Report ({timestamp}) ===")
        print(f"Uptime: {uptime:.1f}s")
        
        for gpu_id, gpu_info in gpu_data.items():
            metric = metrics.get(gpu_id, {})
            print(f"\n{gpu_id}: {gpu_info['name']}")
            print(f"  Memory: {gpu_info['memory_used_mb']}/{gpu_info['memory_total_mb']} MB ({metric.get('memory_usage_pct', 0):.1f}%)")
            print(f"  GPU Usage: {gpu_info['utilization_gpu']}%")
            print(f"  Temperature: {gpu_info['temperature_c']}¬∞C")
            print(f"  Power: {gpu_info['power_w']:.1f}W")
            print(f"  Performance Score: {metric.get('performance_score', 0):.1f}/100")
            print(f"  Optimal: {'‚úÖ' if metric.get('is_optimal', False) else '‚ùå'}")
    
    def get_optimization_recommendations(self, gpu_data: Dict, metrics: Dict) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        recommendations = []
        
        for gpu_id, gpu_info in gpu_data.items():
            metric = metrics.get(gpu_id, {})
            
            # –ê–Ω–∞–ª–∏–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏
            if metric.get('memory_usage_pct', 0) < 70:
                recommendations.append(f"{gpu_id}: –£–≤–µ–ª–∏—á—å—Ç–µ gpu-layers –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
            elif metric.get('memory_usage_pct', 0) > 95:
                recommendations.append(f"{gpu_id}: –£–º–µ–Ω—å—à–∏—Ç–µ gpu-layers –∏–ª–∏ ctx-size –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏")
            
            # –ê–Ω–∞–ª–∏–∑ —É—Ç–∏–ª–∏–∑–∞—Ü–∏–∏ GPU
            if gpu_info['utilization_gpu'] < 30:
                recommendations.append(f"{gpu_id}: GPU –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ batch-size –∏ threads")
            
            # –ê–Ω–∞–ª–∏–∑ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã
            if gpu_info['temperature_c'] > 75:
                recommendations.append(f"{gpu_id}: –í—ã—Å–æ–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –æ—Ö–ª–∞–∂–¥–µ–Ω–∏–µ")
        
        return recommendations
    
    def monitor_continuously(self, interval: int = 5, max_iterations: Optional[int] = None):
        """–ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        print(f"üöÄ –ó–∞–ø—É—Å–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ GPU –∫–∞–∂–¥—ã–µ {interval} —Å–µ–∫—É–Ω–¥")
        print(f"üìù –õ–æ–≥ —Ñ–∞–π–ª: {self.log_file}")
        print("–ù–∞–∂–º–∏—Ç–µ Ctrl+C –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏\n")
        
        iteration = 0
        try:
            while True:
                if max_iterations and iteration >= max_iterations:
                    break
                
                gpu_data = self.get_gpu_info()
                if gpu_data:
                    metrics = self.calculate_performance_metrics(gpu_data)
                    self.log_performance(gpu_data, metrics)
                    
                    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
                    recommendations = self.get_optimization_recommendations(gpu_data, metrics)
                    if recommendations:
                        print("\nüîß –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò:")
                        for rec in recommendations:
                            print(f"  ‚Ä¢ {rec}")
                
                iteration += 1
                time.sleep(interval)
                
        except KeyboardInterrupt:
            print(f"\n‚èπÔ∏è  –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ—Å–ª–µ {iteration} –∏—Ç–µ—Ä–∞—Ü–∏–π")
            print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {self.log_file}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    import argparse
    
    parser = argparse.ArgumentParser(description="GPU Performance Monitor for Text Generation WebUI")
    parser.add_argument("--interval", "-i", type=int, default=5, help="–ò–Ω—Ç–µ—Ä–≤–∞–ª –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö")
    parser.add_argument("--iterations", "-n", type=int, help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π")
    parser.add_argument("--log-file", "-l", default="gpu_performance.log", help="–§–∞–π–ª –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è")
    
    args = parser.parse_args()
    
    monitor = GPUMonitor(log_file=args.log_file)
    monitor.monitor_continuously(interval=args.interval, max_iterations=args.iterations)

if __name__ == "__main__":
    main()
